{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7bc9177",
   "metadata": {},
   "source": [
    "<h3>üß† Types of Neural Network Architectures</h3>\n",
    "\n",
    "<div style=\"font-size: 12px; width: 90%;\">\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Type</th>\n",
    "      <th>Layers</th>\n",
    "      <th>Params</th>\n",
    "      <th>Train Time</th>\n",
    "      <th>Complexity</th>\n",
    "      <th>Applications</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Shallow</td>\n",
    "      <td>1‚Äì3</td>\n",
    "      <td>1K‚Äì10K</td>\n",
    "      <td>Minutes‚ÄìHours</td>\n",
    "      <td>Simple</td>\n",
    "      <td>Linear reg; Binary cls; Feature extract</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Medium</td>\n",
    "      <td>4‚Äì10</td>\n",
    "      <td>100K‚Äì1M</td>\n",
    "      <td>Hours‚ÄìDays</td>\n",
    "      <td>Moderate</td>\n",
    "      <td>Image cls (CNN); LM (RNN); Speech recog</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Deep</td>\n",
    "      <td>11‚Äì50</td>\n",
    "      <td>1M‚Äì10M</td>\n",
    "      <td>Days‚ÄìWeeks</td>\n",
    "      <td>High</td>\n",
    "      <td>Obj detect (YOLO); Seg (FCN); NLP</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Very Deep</td>\n",
    "      <td>51‚Äì100+</td>\n",
    "      <td>10M‚Äì100M+</td>\n",
    "      <td>Weeks‚ÄìMonths</td>\n",
    "      <td>Very High</td>\n",
    "      <td>SOTA vision; Adv NLP (QA, MT)</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dbbd8b",
   "metadata": {},
   "source": [
    "‚úÖ **Universal Approximation Theorem**:  \n",
    "A shallow neural network (with one hidden layer) can mimic any complex function accurately, if it has enough neurons and a suitable activation¬†function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f41214",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; margin-bottom:6px;\">üì¶ Deep Learning Architectures</h3>\n",
    "\n",
    "<style>\n",
    "  .compact-grid {\n",
    "    display: grid;\n",
    "    grid-template-columns: 160px auto;\n",
    "    row-gap: 2px;\n",
    "    font-size: 13px;\n",
    "    font-family: sans-serif;\n",
    "  }\n",
    "  .compact-grid b {\n",
    "    white-space: nowrap;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<b style=\"font-size:14px;\">1. ANN Architectures</b>\n",
    "<div class=\"compact-grid\">\n",
    "  <b>McCulloch-Pitts</b> <span>Binary threshold model.</span>\n",
    "  <b>Hebbian Network</b> <span>‚ÄúNeurons that fire together, wire together.‚Äù</span>\n",
    "  <b>Perceptron / MLP</b> <span>Basic/stacked feedforward layers.</span>\n",
    "  <b>ADALINE / MADALINE</b> <span>Linear adaptive models.</span>\n",
    "  <b>Backpropagation</b> <span>Error-driven learning for MLPs.</span>\n",
    "  <b>RBF Networks</b> <span>Use Gaussian activations.</span>\n",
    "</div>\n",
    "\n",
    "<b style=\"font-size:14px;\">2. Vision Models</b>\n",
    "<div class=\"compact-grid\">\n",
    "  <b>Image Classification</b> <span>Label entire image.</span>\n",
    "  <b>Object Detection</b> <span>Locate + classify objects.</span>\n",
    "  <b>Image Segmentation</b> <span>Semantic, Instance, Panoptic.</span>\n",
    "</div>\n",
    "\n",
    "<b style=\"font-size:14px;\">3. NLP Models</b>\n",
    "<div class=\"compact-grid\">\n",
    "  <b>RNN Family</b> <span>RNN, LSTM, GRU, etc.</span>\n",
    "  <b>Transformer</b> <span>Self-attention architecture.</span>\n",
    "  <b>Pretrained</b> <span>BERT, RoBERTa, T5...</span>\n",
    "  <b>LLMs</b> <span>GPT, LLaMA ‚Äî autoregressive.</span>\n",
    "</div>\n",
    "\n",
    "<b style=\"font-size:14px;\">4. Generative Models</b>\n",
    "<div class=\"compact-grid\">\n",
    "  <b>Autoencoders</b> <span>AE, VAE ‚Äî latent encoding.</span>\n",
    "  <b>GANs</b> <span>Adversarial generation.</span>\n",
    "  <b>Flow Models</b> <span>RealNVP, Glow.</span>\n",
    "  <b>Diffusion</b> <span>DDPM, Stable Diffusion.</span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ea456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6b070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801fe3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0fa27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1340b08d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70430e69",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bd69e51",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size:20px;\">üß† NLP Model Timeline (1986‚Äì2025)</h2>\n",
    "\n",
    "<table style=\"font-size:13px; font-family:sans-serif; border-collapse: collapse; margin-bottom: 16px;\">\n",
    "  <tr><td><b>1986</b></td><td>RNN ‚Äì Basic sequential modeling</td></tr>\n",
    "  <tr><td><b>1997</b></td><td>LSTM ‚Äì Long-term memory via gating</td></tr>\n",
    "  <tr><td><b>2014</b></td><td>GRU, Bi-RNN, Stacked RNN, Seq2Seq, Additive Attention (Bahdanau)</td></tr>\n",
    "  <tr><td><b>2015</b></td><td>Multiplicative Attention (Luong)</td></tr>\n",
    "  <tr><td><b>2017</b></td><td>Transformer ‚Äì Self & Cross Attention</td></tr>\n",
    "  <tr><td><b>2018</b></td><td>BERT, GPT‚Äë1</td></tr>\n",
    "  <tr><td><b>2019</b></td><td>RoBERTa, DistilBERT, ALBERT, XLNet, ERNIE, GPT‚Äë2, MarianMT, BART</td></tr>\n",
    "  <tr><td><b>2020</b></td><td>T5/mT5, ELECTRA, DeBERTa, PEGASUS, ViT, Reformer, Linformer, Performer, BigBird, Longformer</td></tr>\n",
    "  <tr><td><b>2021</b></td><td>Mistral 7B, Switch Transformer, CLIP</td></tr>\n",
    "  <tr><td><b>2022</b></td><td>FlashAttention, BLIP, Flamingo, Perceiver IO</td></tr>\n",
    "  <tr><td><b>2023</b></td><td>GPT‚Äë4, LLaMA‚Äë1/2, DeepSeek (LLM + Coder)</td></tr>\n",
    "  <tr><td><b>2024</b></td><td>LLaMA‚Äë3.0 (Apr), LLaMA‚Äë3.1 / Mistral L2 (Jul), DeepSeek‚ÄëV3 (Dec), R1‚ÄëLite (Nov)</td></tr>\n",
    "  <tr><td><b>2025</b></td><td>Jan: DeepSeek‚ÄëR1, Mar: V3‚Äë0324, May: Devstral (Small‚Äë2505), Mixtral (MoE)</td></tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"font-size:16px;\">üîπ 1. RNN Family ‚Äì Early Sequence Models</h3>\n",
    "<p><i>Goal:</i> Handle sequential data by using memory of past tokens.</p>\n",
    "\n",
    "<ul style=\"font-size:13px;\">\n",
    "  <li><b>RNN:</b> Learns temporal patterns, but suffers from vanishing gradients.</li>\n",
    "  <li><b>LSTM:</b> Adds gates (input, forget, output) for long-term memory.</li>\n",
    "  <li><b>GRU:</b> Uses update/reset gates; simpler than LSTM.</li>\n",
    "  <li><b>Bidirectional RNN:</b> Processes sequences in both directions.</li>\n",
    "  <li><b>Stacked RNN:</b> Multiple RNN layers stacked for deeper features.</li>\n",
    "  <li><b>Encoder-Decoder:</b> Maps input ‚Üí output sequences, used in translation.</li>\n",
    "</ul>\n",
    "\n",
    "<h3 style=\"font-size:16px;\">üîπ 2. Attention Mechanisms ‚Äì Beyond RNNs</h3>\n",
    "<p><i>Goal:</i> Focus on relevant input parts during prediction.</p>\n",
    "\n",
    "<ul style=\"font-size:13px;\">\n",
    "  <li><b>Additive Attention:</b> Feedforward-based alignment (Bahdanau).</li>\n",
    "  <li><b>Multiplicative Attention:</b> Dot-product based (Luong).</li>\n",
    "  <li><b>Cross-Attention:</b> Decoder attends to encoder outputs.</li>\n",
    "  <li><b>Self-Attention:</b> Token attends to all others; base of Transformers.</li>\n",
    "  <li><b>Flash Attention:</b> Fast, memory-efficient self-attention.</li>\n",
    "</ul>\n",
    "\n",
    "<h3 style=\"font-size:16px;\">üîπ 3. Transformer Era ‚Äì Scalable Parallel Processing</h3>\n",
    "<p><i>Goal:</i> Leverage parallelism & self-attention to scale beyond RNNs.</p>\n",
    "\n",
    "<ul style=\"font-size:13px;\">\n",
    "  <li><b>Transformer (2017):</b> Encoder-Decoder, multi-head, positional encoding.</li>\n",
    "</ul>\n",
    "\n",
    "<b>Efficient Transformers</b>\n",
    "<ul style=\"font-size:13px;\">\n",
    "  <li><b>BigBird / Longformer:</b> Sparse/windowed attention for long texts.</li>\n",
    "  <li><b>Reformer:</b> Memory-efficient using hashing + reversible layers.</li>\n",
    "  <li><b>Switch Transformer:</b> MoE-based dynamic routing.</li>\n",
    "  <li><b>Performer / Linformer:</b> Linear-time attention.</li>\n",
    "  <li><b>Flash Attention:</b> GPU-optimized fast attention.</li>\n",
    "</ul>\n",
    "\n",
    "<b>Vision & Multimodal Transformers</b>\n",
    "<ul style=\"font-size:13px;\">\n",
    "  <li><b>ViT:</b> Transformer on image patches.</li>\n",
    "  <li><b>Perceiver IO:</b> Handles text, vision, audio.</li>\n",
    "  <li><b>CLIP / BLIP / Flamingo:</b> Vision+language tasks.</li>\n",
    "</ul>\n",
    "\n",
    "<h3 style=\"font-size:16px;\">üîπ 4. Pretrained Transformers ‚Äì Generalizable Models</h3>\n",
    "<p><i>Goal:</i> Learn general-purpose representations via self-supervised training.</p>\n",
    "\n",
    "<b>Encoder-only</b>  \n",
    "<ul style=\"font-size:13px;\">\n",
    "  <li><b>BERT:</b> Masked LM; bidirectional context.</li>\n",
    "  <li><b>RoBERTa:</b> BERT+ longer training, more data.</li>\n",
    "  <li><b>DistilBERT:</b> Compressed version with 95% accuracy.</li>\n",
    "  <li><b>ALBERT:</b> Lightweight BERT with parameter sharing.</li>\n",
    "  <li><b>DeBERTa:</b> Disentangled attention mechanism.</li>\n",
    "  <li><b>ELECTRA:</b> Detects replaced tokens (generator-discriminator).</li>\n",
    "</ul>\n",
    "\n",
    "<b>Encoder-Decoder</b>  \n",
    "<ul style=\"font-size:13px;\">\n",
    "  <li><b>T5 / mT5:</b> Text-to-text for all tasks (multilingual).</li>\n",
    "  <li><b>PEGASUS:</b> Summarization-focused pretraining.</li>\n",
    "  <li><b>BART:</b> Denoising + sequence-to-sequence generation.</li>\n",
    "  <li><b>MarianMT:</b> Efficient multilingual translator.</li>\n",
    "</ul>\n",
    "\n",
    "<b>Hybrid</b>  \n",
    "<ul style=\"font-size:13px;\">\n",
    "  <li><b>XLNet:</b> Combines autoregressive and autoencoding.</li>\n",
    "  <li><b>ERNIE:</b> Integrates structured knowledge (e.g., KG).</li>\n",
    "</ul>\n",
    "\n",
    "<h3 style=\"font-size:16px;\">üîπ 5. Generative Models ‚Äì Foundation of LLMs</h3>\n",
    "<p><i>Goal:</i> Autoregressive generation of fluent, coherent text.</p>\n",
    "\n",
    "<ul style=\"font-size:13px;\">\n",
    "  <li><b>GPT-1:</b> Decoder-only Transformer.</li>\n",
    "  <li><b>GPT-2:</b> Large-scale, paragraph coherence.</li>\n",
    "  <li><b>GPT-3:</b> 175B params; prompt learning.</li>\n",
    "  <li><b>GPT-4:</b> Multimodal, highly aligned reasoning.</li>\n",
    "  <li><b>Open-Source:</b> LLaMA, Mistral, DeepSeek, Falcon.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc105ecf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
